{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESI HumanForYou\n",
    "\n",
    "L'entreprise de produits pharmaceutiques HumanForYou basée en Inde emploie environ 4000 personnes. Cependant, chaque année elle subit un turn-over d'environ 15% de ses employés nécessitant de retrouver des profils similaires sur le marché de l'emploi.\n",
    "\n",
    "La direction trouve que ce niveau de turn-over n'est pas bon pour l'entreprise car :\n",
    "\n",
    "* Les projets sur lesquels étaient les employés quittant la société prennent du retard ce qui nuit à la réputation de l'entreprise auprès de ses clients et partenaires.\n",
    "\n",
    "* Un service de ressources humaines de taille conséquente doit être conservé car il faut avoir les moyens de trouver les nouvelles recrues.\n",
    "\n",
    "* Du temps est perdu à l'arrivée des nouveaux employés car ils doivent très souvent être formés et ont besoin de temps pour devenir pleinement opérationnels dans leur nouvel environnement.\n",
    "\n",
    "Le direction fait donc appel à notre équipe, spécialistes de l'analyse de données, pour déterminer les facteurs ayant le plus d'influence sur ce taux de turn-over et lui proposer des modèles afin d'avoir des pistes d'amélioration pour donner à leurs employés l'envie de rester.\n",
    "\n",
    "### Table des matières\n",
    "\n",
    "1. [Préparation de l'environnement](#chapter1)\n",
    "    1. [Importation des librairies](#section_1_1)\n",
    "    2. [Importation des données](#Section_1_2)\n",
    "2. [Visualisation des données](#chapter2)\n",
    "    1. [Données du service des ressources humaines](#section_2_1)\n",
    "    2. [Dernière évaluation du manager](#section_2_2)\n",
    "    3. [Enquête qualité de vie au travail](#section_2_3)\n",
    "    4. [Horaires de travail](#section_2_4)\n",
    "3. [Transformation des données](#chapter3)\n",
    "    1. [Calcul des durées de travail](#section_3_1)\n",
    "    2. [Concaténation des données](#section_3_2)\n",
    "    3. [Ajout de valeur](#section_3_3)\n",
    "    4. [Suppression colonne](#section_3_4)\n",
    "    5. [Normalisation](#section_3_5)\n",
    "    6. [Standardisation](#section_3_6)\n",
    "    7. [Création des jeux de données ](#section_3_7)\n",
    "4. [Analyses statistiques](#chapter4)\n",
    "    1. [Analyse des données entrantes](#section_4_1)\n",
    "    2. [Analyse de l'attrition](#section_4_2)\n",
    "5. [Algorithmes](#chapter5)\n",
    "6. [Evaluation des modèles](#chapter6)\n",
    "\n",
    "\n",
    "<a id=\"chapter1\"></a>\n",
    "## Préparation de l'environnement\n",
    "\n",
    "<a id=\"section_1_1\"></a>\n",
    "### Importation des librairies\n",
    "\n",
    "Tout d'abord, nous devons importer toutes les bibliothèques que nous utiliserons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import default_rng\n",
    "from datetime import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from numpy import argmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_1_2\"></a>\n",
    "### Importation des données\n",
    "\n",
    "Les données utilisées pour nos analyses proviennent de fichier CSV depuis Github et doivent être charger dans nos variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des données depuis Github \n",
    "general_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/general_data.csv\"\n",
    "manager_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/manager_survey_data.csv\"\n",
    "employee_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/employee_survey_data.csv\"\n",
    "in_time_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/in_time.csv\"\n",
    "out_time_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/out_time.csv\"\n",
    "\n",
    "#Lecture des csv\n",
    "general_info_data = pd.read_csv(general_url)\n",
    "manager_survey_data = pd.read_csv(manager_url)\n",
    "employee_survey_data = pd.read_csv(employee_url)\n",
    "in_time_data = pd.read_csv(in_time_url)\n",
    "out_time_data = pd.read_csv(out_time_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chapter2\"></a>\n",
    "## Visualisation des données\n",
    "\n",
    "Dans un premier temps, nous regardons toutes les données que nous avons. Un certain nombre de données concernant les employés nous a donc été transmis par le service des ressources humaines ainsi que par des fiches d'évaluation.\n",
    "\n",
    "Les données ont été anonymisées : un employé de l'entreprise sera représenté par le même EmployeeID dans l'ensemble des fichiers qui suivent.\n",
    "\n",
    "<a id=\"section_2_1\"></a>\n",
    "### Données du service des ressources humaines\n",
    "\n",
    "Pour chaque employé, le service des ressources humaines vous confie les informations en sa possession :\n",
    "\n",
    "* Age : L'âge de l'employé en 2015.\n",
    "* Attrition : L'objet de notre étude, est-ce que l'employé a quitté l'entreprise durant l'année 2016 ?\n",
    "\n",
    "* BusinessTravel : A quel fréquence l'employé a été amené à se déplacer dans le cadre de son travail en 2015 ? (Non-Travel = jamais, Travel_Rarely= rarement, Travel_Frequently = fréquemment)\n",
    "\n",
    "* DistanceFromHome : Distance en km entre le logement de l'employé et l'entreprise.\n",
    "\n",
    "* Education : Niveau d'étude : 1=Avant College (équivalent niveau Bac), 2=College (équivalent Bac+2), 3=Bachelor (Bac+3), 4=Master (Bac+5) et 5=PhD (Thèse de doctorat).\n",
    "\n",
    "* EducationField : Domaine d'étude, matière principale\n",
    "\n",
    "* EmployeeCount : booléen à 1 si l'employé était compté dans les effectifs en 2015.\n",
    "\n",
    "* EmployeeId : l'identifiant d'un employé\n",
    "\n",
    "* Gender : Sexe de l'employé\n",
    "\n",
    "* JobLevel : Niveau hiérarchique dans l'entreprise de 1 à 5\n",
    "\n",
    "* JobRole : Métier dans l'entreprise\n",
    "\n",
    "* MaritalStatus : Statut marital du salarié (Célibataire, Marié ou Divorcé).\n",
    "\n",
    "* MonthlyIncome : Salaire brut en roupies par mois\n",
    "\n",
    "* NumCompaniesWorked : Nombre d'entreprises pour lequel le salarié a travaillé avant de rejoindre HumanForYou.\n",
    "\n",
    "* Over18 : Est-ce que le salarié a plus de 18 ans ou non ?\n",
    "\n",
    "* PercentSalaryHike : % d'augmentation du salaire en 2015.\n",
    "\n",
    "* StandardHours : Nombre d'heures par jour dans le contrat du salarié.\n",
    "\n",
    "* StockOptionLevel : Niveau d'investissement en actions de l'entreprise par le salarié.\n",
    "\n",
    "* TotalWorkingYears : Nombre d'années d'expérience en entreprise du salarié pour le même type de poste.\n",
    "\n",
    "* TrainingTimesLastYear : Nombre de jours de formation en 2015\n",
    "\n",
    "* YearsAtCompany : Ancienneté dans l'entreprise\n",
    "\n",
    "* YearsSinceLastPromotion : Nombre d'années depuis la dernière augmentation individuelle\n",
    "\n",
    "* YearsWithCurrentManager : Nombre d'années de collaboration sous la responsabilité du manager actuel de l'employé.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_info_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi intéressant de connaitre le type des variables qui composent le fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of general_info_data :',general_info_data.shape)\n",
    "general_info_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_2_2\"></a>\n",
    "### Dernière évaluation du manager\n",
    "\n",
    "Ce fichier contient la dernière évaluation de chaque employé faite pas son manager en février 2015.\n",
    "\n",
    "Il contient les données suivantes :\n",
    "\n",
    "* L'identifiant de l'employé : EmployeeID\n",
    "\n",
    "* Une évaluation de son implication dans son travail notée 1 ('Faible'), 2 (\"Moyenne\"), 3 (\"Importante\") ou 4 (\"Très importante\") : JobInvolvement\n",
    "\n",
    "* Une évaluation de son niveau de performance annuel pour l'entreprise notée 1 (\"Faible\"), 2 (\"Bon\"), 3 (\"Excellent\") ou 4 (\"Au delà des attentes\") : PerformanceRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_survey_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_survey_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_2_3\"></a>\n",
    "### Enquête qualité de vie au travail\n",
    "\n",
    "Ce fichier provient d'une enquête soumise aux employés en juin 2015 par le service RH pour avoir un retour concernant leur qualité de vie au travail.\n",
    "\n",
    "Une organisation avait été mise en place pour que chacun puisse répondre à ce questionnaire sur son lieu de travail en concertation avec les managers mais il n'y avait pas d'obligation.\n",
    "\n",
    "Les employés devaient répondre à 3 questions sur le niveau de satisfaction concernant :\n",
    "\n",
    "* L'environnement de travail, noté 1 (\"Faible\"), 2 (\"Moyen\"), 3 (\"Élevé\") ou 4 (\"Très élevé\") : EnvironmentSatisfaction\n",
    "\n",
    "* Son travail, noté de 1 à 4 comme précédemment : JobSatisfaction\n",
    "\n",
    "* Son équilibre entre vie professionnelle et vie privée, noté 1 (\"Mauvais\"), 2 (\"Satisfaisant\"), 3 (\"Très satisfaisant\") ou 4 (\"Excellent\") : WorkLifeBalance\n",
    "\n",
    "Lorsque un employé n'a pas répondu à une question, le texte \"NA\" apparaît à la place de la note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_survey_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_survey_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_2_4\"></a>\n",
    "### Horaires de travail\n",
    "\n",
    "Des badgeuses sont installées et utilisées dans l'entreprise depuis quelques années. Il a été jugé opportun par la direction de nous transmettre les horaires d'entrée et de sortie des employés sur une période de l'année choisie représentative d'une activité moyenne pour l'ensemble des services.\n",
    "\n",
    "Nous avons donc 2 fichiers traçants les horaires d'arrivée à leur poste et de départ de leur poste de l'ensemble des employés par date sur une période allant du 1er janvier au 31 décembre 2015.\n",
    "\n",
    "Données d'arrivée des employées:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_time_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_time_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données de départ des employées: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_time_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_time_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chapter3\"></a>\n",
    "## Transformation des données\n",
    "\n",
    "Plusieurs données ne peuvent pas être exploiter en l'état, il faut donc trier et retravailler les données.\n",
    "\n",
    "<a id=\"section_3_1\"></a>\n",
    "### Calcul des durées de travail\n",
    "\n",
    "Les données de temps ne sont pas exploitables sous cette forme, il faut donc les tranformer.\n",
    "\n",
    "Avoir des heures d'entrées et de sortie de nos employés n'est pas très significatifs, c'est pour cela que nous remplaçons toutes les valeurs par la moyenne de temps de travail de chaque employé.\n",
    "\n",
    "Cependant : \n",
    "* Les dates sont stockées en tant que chaine de caractère et il est compliqué de les exploiter.\n",
    "* Cetaines données valent \"NaN\", ce qui veut dire qu'un employé a été absent au travail\n",
    "\n",
    "Pour remédier à ça, nous transformons les données en objet Datetime. De plus lorsqu'un employé est absent au travail, son temps moyen de travail est de 0 donc nous remplaçons les NaN par 0.\n",
    "\n",
    "Avant de mettre en place nos changements, nous devons renommer la colonne (sans nom) qui correspond aux IDs des employés. Cette actions est prise puisque dans le csv nous avons le même nombre de ligne que sur les autres csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renommage des colonnes sans nom de nos csv in et out\n",
    "in_time_data.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
    "in_time_data.set_index('EmployeeID', inplace=True)\n",
    "in_time_data\n",
    "out_time_data.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
    "out_time_data.set_index('EmployeeID', inplace=True)\n",
    "\n",
    "# Suppression des colonnesoù l'employée est absent (valeur NaN)\n",
    "in_time_data=in_time_data.dropna(axis=1,how='all')\n",
    "out_time_data=out_time_data.dropna(axis=1,how='all')\n",
    "\n",
    "# Remplacement des NaN par 0\n",
    "in_time_data.fillna(0, inplace=True)\n",
    "out_time_data.fillna(0, inplace=True)\n",
    "\n",
    "out_time_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme nos chaines de caractère en objets datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in in_time_data.columns:\n",
    "    in_time_data[date]=pd.to_datetime(in_time_data[date])\n",
    "    out_time_data[date]=pd.to_datetime(out_time_data[date])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule dans un nouveau dataset le nombre d'heure passé qu'en employé passe au travail par jour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_work_per_day=pd.DataFrame()\n",
    "\n",
    "cols=in_time_data.columns\n",
    "for col in cols:\n",
    "    time_work_per_day[col]=((out_time_data[col] - in_time_data[col]).dt.total_seconds() /3600)\n",
    "\n",
    "time_work_per_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous ajoutons ensuite une colonne représentant : \n",
    "* La moyenne de temps passsé au travail par employé sur l'année 2015 \n",
    "* Le nombre d'absences au travail par employé durant l'année 2015 \n",
    "\n",
    "Les autres colonnes sont ensuite supprimées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_work_per_day['MeanTimeWorkOverYear2015']=round(time_work_per_day.astype(int).mean(axis=1),2)\n",
    "time_work_per_day['absences_par_jour']=(time_work_per_day == 0).astype(int).sum(axis=1)\n",
    "time_work_per_day = time_work_per_day.drop((time_work_per_day.columns[0:-2]), axis = 1)\n",
    "time_work_per_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_3_2\"></a>\n",
    "### Concaténation des données\n",
    "\n",
    "Pour la suite des analyses, nous allons rassembler toutes les données sur une même variable. Comme sur chaque csv, l'ID des employées est inscrit, il est facile de concater les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_time_csv = general_info_data.merge(time_work_per_day, on='EmployeeID')\n",
    "concat_manager_csv = concat_time_csv.merge(manager_survey_data, on='EmployeeID')\n",
    "temp_concat = concat_manager_csv.merge(employee_survey_data, on='EmployeeID')\n",
    "temp_concat = temp_concat.set_index('EmployeeID')\n",
    "temp_concat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide des informations précédentes, nous remarquons plusieurs choses:\n",
    "* Tous les champs ne possèdent pas le même nombre de tuples\n",
    "* Les champs ayants un type objet corréspondent à des variables qualitatives\n",
    "\n",
    "Pour la suite des analyses, nous devons d'abord harmoniser nos données pour ne plus avoir les deux remarques précédentes.\n",
    "\n",
    "<a id=\"section_3_3\"></a>\n",
    "### Ajout de valeur\n",
    "\n",
    "Pour palier au manque de certaines données, nous comblons les valeurs manquantes par la valeur médiane de ses champs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de champs avec des valeurs vides\n",
    "final_data = temp_concat.copy()\n",
    "final_data[final_data.columns[final_data.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout des valeurs médianes\n",
    "final_data.fillna(round(final_data.median()),inplace=True)\n",
    "final_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_3_4\"></a>\n",
    "### Suppression de colonne\n",
    "\n",
    "Il est important de vérifier qu'il n'y est pas des champs avec valeur similaire partout. Cela signifit que l'information n'est pas pertinente et qu'elle peut être supprimer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'aide de ce tableau, nous remarquons qu'il existe des champs à valeur unique :\n",
    "- EmployeeCount : la valeur min et max est égale à 1\n",
    "- Over18 : cette varible possède une unique valeur (unique = 1)\n",
    "- StandardHours : la valeur min et max est égale à 8\n",
    "\n",
    "Nous supprimons donc ces champs pour la suite des travaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.drop(['EmployeeCount', 'Over18', 'StandardHours'], axis=1, inplace = True)\n",
    "final_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_3_5\"></a>\n",
    "### Normalisation\n",
    "\n",
    "Comme dans la suite de ce projet nous devrons utiliser des algorithmes de machine learning, il est important de prendre en compte les recommandations de ses derniers. Comme de nombreux algorithmes d'apprentissage automatique ne peuvent pas fonctionner directement sur des données qualitatives, nous devons prévoir un ensemble de données dont toutes les variables d'entrée et les variables de sortie soient numériques.\n",
    "\n",
    "Afin de n'avoir que des données quantitatives, nous utilisons le One-hot Encoding. Quand une variables n'est pas ordinale, cette solution va créer des variables supplémentaires dans le jeu de donnée pour représenter chacune des catégories.\n",
    "\n",
    "Les champs concernés sont : \"BusinessTravel\",\"Department\",\"EducationField\", \"JobRole\",\"MaritalStatus\", \"Gender\".\n",
    "Et vont être remplacés par : \n",
    "* BusinessTravel_Non-Travel\n",
    "* BusinessTravel_Travel_Frequently\n",
    "* BusinessTravel_Travel_Rarely\n",
    "* Department_Human Resources\n",
    "* Department_Research & Development\n",
    "* Department_Sales\n",
    "* EducationField_Human Resources\n",
    "* EducationField_Life Sciences\n",
    "* EducationField_Marketing\n",
    "* EducationField_Medical\n",
    "* EducationField_Other\n",
    "* EducationField_Technical Degree\n",
    "* JobRole_Healthcare Representative\n",
    "* JobRole_Human Resources\n",
    "* JobRole_Manufacturing Director\t\n",
    "* JobRole_Research Director\t\n",
    "* JobRole_Research Scientist\t\n",
    "* JobRole_Sales Executive\t\n",
    "* JobRole_Sales Representative\t\n",
    "* MaritalStatus_Divorced\t\n",
    "* MaritalStatus_Married\t\n",
    "* MaritalStatus_Single\t\n",
    "* Gender_Female\t\n",
    "* Gender_Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot Encoding\n",
    "final_data2 = pd.get_dummies(final_data, \n",
    "prefix=[\"BusinessTravel\",\"Department\",\"EducationField\", \"JobRole\",\"MaritalStatus\", \"Gender\"],\n",
    "columns=[\"BusinessTravel\",\"Department\",\"EducationField\", \"JobRole\",\"MaritalStatus\", \"Gender\"])\n",
    "final_data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_3_6\"></a>\n",
    "\n",
    "### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Suppression de la colonne Attrition\n",
    "final_data3 = final_data2.drop(\"Attrition\",axis=1)\n",
    "\n",
    "# Normalisation des données en utilisant le z-score \n",
    "norm = StandardScaler().fit_transform(final_data3)\n",
    "final_data3 = pd.DataFrame(norm, columns=final_data3.columns)\n",
    "final_data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression cols\n",
    "cols_pas_ethic = [\"Gender_Male\", \"Gender_Female\", \"YearsWithCurrManager\", \"PerformanceRating\", \"Age\", \"MaritalStatus_Single\", \"MaritalStatus_Married\", \"MaritalStatus_Divorced\"]\n",
    "cols_big_corr = [\"Department_Sales\", \"BusinessTravel_Travel_Rarely\"]\n",
    "\n",
    "final_data4 = final_data3.drop(cols_pas_ethic,axis=1)\n",
    "final_data4 = final_data4.drop(cols_big_corr,axis=1)\n",
    "final_data4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_3_7\"></a>\n",
    "\n",
    "### Création des jeux de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définitions de nos variables X et y\n",
    "X = final_data4\n",
    "y = final_data2[\"Attrition\"]\n",
    "\n",
    "\n",
    "seed =42\n",
    "test_size = 0.2\n",
    "# Fixer un seed pour avoir les mêmes résultats à chaque essai\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Séparer les données d'entrainement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la suite de cette section, nous avons deux ensembles de données nettoyés et complets:\n",
    "* final_data :  données qualitatives et quantitatives\n",
    "* final_data2 : données uniquement quantitatives \n",
    "* final_data3 : données uniquement quantitatives et standardisées \n",
    "\n",
    "\n",
    "<a id=\"chapter4\"></a>\n",
    "\n",
    "## Analyses statistiques\n",
    "\n",
    "Nous séparons nos données en deux parties : \n",
    "-  Les valeurs entrantes qui correspondent à tous les paramêtres qui possèdent différentes valeurs (Ex: DistanceFromHome, Education, Age ...)\n",
    "- La valeur de sortie (variable 'Attrition') qui permet de savoir si l'employée à quitté ou non l'entreprise l'année suivante.\n",
    "\n",
    "Pour cela, nous allons analyser nos deux groupes.\n",
    "\n",
    "<a id=\"section_4_1\"></a>\n",
    "### Analyste des données entrantes\n",
    "\n",
    "#### Histogramme \n",
    "\n",
    "Concernant les données quantitatives, nous affichons nos valeurs de façon visuelle afin d'avoir un meilleur appercu de l'allure de nos données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corrélation des données\n",
    "\n",
    "Maintenant nous voulons voir si nos valeurs possèdent des liens entre-elles. Pour cela nous utilisons une matrice de corrélation. Elle permet d'évaluer la dépendence entre plusieurs variables en même temps. Le résultat est une table contenant les coefficients de corrélation entre chaque variable et les autres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "corr_matrix = final_data2.corr(method=\"pearson\")\n",
    "\n",
    "plt.figure(figsize=(40,30))\n",
    "sns.heatmap(corr_matrix, annot= True, cbar=True, cmap=\"Blues_r\")\n",
    "plt.show()\n",
    "\n",
    "corr_matrix = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "corr_matrix = corr_matrix.unstack().reset_index()\n",
    "corr_matrix.columns = [\"feature1\", \"feature2\", \"Correlation\"]\n",
    "corr_matrix.dropna(subset = ['Correlation'], inplace = True)\n",
    "corr_matrix['Correlation'] = round(corr_matrix['Correlation'], 2)\n",
    "corr_matrix['Correlation'] = abs(corr_matrix['Correlation'])\n",
    "corr_matrix = corr_matrix.sort_values(by = 'Correlation', ascending = False)\n",
    "value_high_corr = corr_matrix[corr_matrix['Correlation']>0.7]\n",
    "\n",
    "value_high_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_4_2\"></a>\n",
    "\n",
    "### Analyse de l'attrition\n",
    "\n",
    "Maintenant que nous avons analyser les paramêtres indépendament de l'attrition, nous allons regarder leur influence sur cette dernière.\n",
    "\n",
    "#### Courbes de densité superposées\n",
    "\n",
    "A l'aide des courbes de densité superposées, nous regardons la répartition des valeurs quantitatives pour chaque variables en fonction de l'attrition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_chart(df,feature):\n",
    "    ax=sns.kdeplot(df[df['Attrition']=='Yes'][feature],\n",
    "             shade=True,label='Attrition = Yes')\n",
    "    ax=sns.kdeplot(df[df['Attrition']=='No'][feature],\n",
    "                 shade=True,label='Attrition = No')\n",
    "    ax.legend()\n",
    "\n",
    "cols = ['DistanceFromHome','MonthlyIncome','TotalWorkingYears','TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion','PercentSalaryHike','YearsWithCurrManager','MeanTimeWorkOverYear2015','absences_par_jour', \"Age\"]\n",
    "\n",
    "plt.figure(figsize=(40,30))\n",
    "for i, col in enumerate(cols):\n",
    "    ax = plt.subplot(4, 3, i+1)\n",
    "    area_chart(final_data, col)\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cependant comme nous voyons peu de différence à l'oeil nu, nous allons dans un deuxième temps des boites à moustache.\n",
    "\n",
    "#### Boîtes à moustache\n",
    "\n",
    "A l'aide de boites à moustache, nous regardons la répartition des valeurs quantitatives pour chaque variables en fonction de l'attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['DistanceFromHome','MonthlyIncome','TotalWorkingYears','TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion','PercentSalaryHike','YearsWithCurrManager','MeanTimeWorkOverYear2015','absences_par_jour']\n",
    "\n",
    "plot_rows=2\n",
    "plot_cols=5\n",
    "fig = make_subplots(rows=plot_rows, cols=plot_cols,subplot_titles=(cols))\n",
    "\n",
    "col_i = 0\n",
    "for i in range(1, plot_rows + 1):\n",
    "    for j in range(1, plot_cols + 1):\n",
    "        for t in px.box(final_data, x=\"Attrition\", y=cols[col_i]).data:\n",
    "            fig.add_trace(t,row=i, col=j)\n",
    "\n",
    "        col_i=col_i+1\n",
    "fig.update_layout(height=600, width=1200)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogrammes\n",
    "\n",
    "A l'aide des histogrammes, nous regardons la répartition des valeurs qualitatives pour chaque variables en fonction de l'attrition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BusinessTravel', 'Department', 'Education', 'EducationField', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus', 'StockOptionLevel', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']\n",
    "\n",
    "attrition = final_data['Attrition'].tolist()\n",
    "result = {}\n",
    "\n",
    "for col in cols:\n",
    "    current_col = final_data[col].tolist()\n",
    "\n",
    "    #values = {name: \"\", [0,1]}\n",
    "    values = {}\n",
    "    label = []\n",
    "    list_yes = []\n",
    "    list_no = []\n",
    "\n",
    "    for index in range(len(current_col)):\n",
    "\n",
    "        try:\n",
    "            i = label.index(current_col[index])\n",
    "        except:\n",
    "            i = -1\n",
    "        \n",
    "        # On ajoute\n",
    "        if(i != -1):\n",
    "            if(attrition[index] == 'Yes'):\n",
    "                list_yes[i] += 1\n",
    "            else:\n",
    "                list_no[i] += 1\n",
    "        # On créée\n",
    "        else:\n",
    "            label.append(current_col[index])\n",
    "            if(attrition[index] == 'Yes'):\n",
    "                list_yes.append(1)\n",
    "                list_no.append(0)\n",
    "            else:\n",
    "                list_yes.append(0)\n",
    "                list_no.append(1)\n",
    "    pourcent_yes = []\n",
    "    pourcent_no = []\n",
    "\n",
    "    for j in range(len(list_yes)):\n",
    "        no = list_no[j]\n",
    "        yes = list_yes[j]\n",
    "        total = no + yes\n",
    "        pourcent_yes.append(\"{}%\".format(round(100 * yes / total)))\n",
    "        pourcent_no.append(\"{}%\".format(round(100 * no / total)))\n",
    "    \n",
    "    plot_rows=7\n",
    "    plot_cols=2\n",
    "    fig = make_subplots(rows=plot_rows, cols=plot_cols,subplot_titles=(cols))\n",
    "\n",
    "    for ii in range(1, plot_rows + 1):\n",
    "        for jj in range(1, plot_cols + 1): \n",
    "            show=False\n",
    "            if (ii == 1 and jj == 1):\n",
    "                show=True\n",
    "            fig.add_trace(go.Bar(\n",
    "                                name='Yes',\n",
    "                                x=label,\n",
    "                                y=list_yes,\n",
    "                                offsetgroup=0,\n",
    "                                text = pourcent_yes,\n",
    "                                marker_color=\"steelblue\",\n",
    "                                showlegend=show\n",
    "                            ),row=ii, col=jj)\n",
    "            fig.add_trace(go.Bar(\n",
    "                                name='No',\n",
    "                                x=label,\n",
    "                                y=list_no,\n",
    "                                offsetgroup=1,\n",
    "                                text = pourcent_no,\n",
    "                                marker_color=\"coral\",\n",
    "                                showlegend=show\n",
    "                            ),row=ii, col=jj)\n",
    "fig.update_layout(height=1800, width=1000, title=\"Attrition pour chaque colonnes\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chapter5\"></a>\n",
    "## Algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_label = y_train.copy()\n",
    "y_train_label.where(y_train_label == \"Yes\", 0, inplace=True)\n",
    "y_train_label.where(y_train_label == 0, 1, inplace=True)\n",
    "y_train_label = y_train_label.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = y_test.copy()\n",
    "y_test_label.where(y_test_label == \"Yes\", 0, inplace=True)\n",
    "y_test_label.where(y_test_label == 0, 1, inplace=True)\n",
    "y_test_label = y_test_label.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listes des algorithmes  \n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \"KNN\": KNeighborsClassifier(),\n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"Perceptron\": Perceptron(),\n",
    "          \"Descente de gradient\": SGDClassifier()}\n",
    "\n",
    "# fonction appliquant un fit et score sur chacun des modeles\n",
    "def fit_and_score(models, X_train, y_train_label):\n",
    "    \n",
    "    # Fixer un seed pour avoir les mêmes résultats à chaque essai \n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Dictionnaire pour sauvegarder les scores\n",
    "    fitted_model = {}\n",
    "    for name, model in models.items():\n",
    "        # Fit le modèle\n",
    "        model.fit(X_train, y_train_label)\n",
    "        fitted_model[name] = model\n",
    "        \n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = fit_and_score(models=models, X_train=X_train, y_train_label=y_train_label)\n",
    "fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Comparaison des résultats obtenus\n",
    "# model_compare = pd.DataFrame(model_scores, index=[\"accuracy\"])\n",
    "# model_compare.T.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"chapter5\"></a>\n",
    "\n",
    "## Evaluation des modèles\n",
    "\n",
    "<a id=\"section_5_1\"></a>\n",
    "### Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction appliquant xxxxxxxxxxxxxxxxxxx\n",
    "def evaluation_accuracy(models, X, y):\n",
    "    \n",
    "    tabl = pd.DataFrame(columns=['Algorithme', 'Accuracy Score Train', 'Accuracy Score Test', 'Différence'])\n",
    "    tabl.style.hide_index()\n",
    "\n",
    "    i = 0   \n",
    "    for name, model in models.items():\n",
    "        # Evaluer le modèle selon le score de chaque algorithme\n",
    "        cross_val = (cross_val_score(model, X, y, cv=10, scoring='accuracy')).mean()\n",
    "        \n",
    "        #\n",
    "        y_pred = model.predict(X)\n",
    "        accuracy_test = accuracy_score(y, y_pred)\n",
    "        \n",
    "        diff = accuracy_test - cross_val\n",
    "        \n",
    "        tabl.loc[i] = [name, cross_val, accuracy_test, diff]\n",
    "        i=i+1\n",
    "        \n",
    "        #confusion matrix\n",
    "        cm = metrics.confusion_matrix(y, y_pred)\n",
    "        \n",
    "        #Visualize the confusion matrix\n",
    "        plt.figure(figsize=(9,9))\n",
    "        sns.heatmap(cm, annot=True, fmt=\".0f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "        plt.ylabel('Actual Class');\n",
    "        plt.xlabel('Predicted Class');\n",
    "        all_sample_title = \"Test Accuracy: %0.2f\" % (cross_val)\n",
    "        plt.title(all_sample_title, size = 15);\n",
    "\n",
    "\n",
    "    return tabl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_accuracy(fitted_model, X_train, y_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter tuning\n",
    "\n",
    "#Données de paramètres\n",
    "\n",
    "param_reglog = [\n",
    "    {'solver': ['newton-cg', 'liblinear'],\n",
    "    'penalty': ['none', 'l1', 'l2']}\n",
    "]\n",
    "\n",
    "param_knn = [\n",
    "    {'n_neighbors' : range(1,10),\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan']}\n",
    "]\n",
    "\n",
    "param_random_forest = [\n",
    "    {'n_estimators' : [10, 50, 100, 200],\n",
    "    'max_depth' : [10, 20, 40, 50],\n",
    "    'max_features': [1, 'auto', 'log2'],\n",
    "    'bootstrap': [True, False]}\n",
    "]\n",
    "\n",
    "param_perceptron = [\n",
    "    {'penalty' : ['l1', 'l2'],\n",
    "    'fit_intercept': [True, False],\n",
    "    'max_iter': [20, 50, 70, 100]}\n",
    "]\n",
    "\n",
    "param_descente = [\n",
    "    {'learning_rate': ['optimal'],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1, 0.3, 0.5],\n",
    "    'loss': ['log', 'perceptron'],\n",
    "    'penalty': ['l1', 'l2']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_method(gs_cv, X, y):\n",
    "    gs_cv.fit(X, y)\n",
    "    gs_cv_best_score = gs_cv.best_score_\n",
    "    gs_cv_best_param = gs_cv.best_params_\n",
    "    gs_cv_best_estimator = gs_cv.best_estimator_\n",
    "    gs_cv_score = cross_val_score(gs_cv_best_estimator, X, y, cv=10).mean()\n",
    "    \n",
    "    return gs_cv_best_score, gs_cv_best_param, gs_cv_best_estimator, gs_cv_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "gs_cv_reglog = GridSearchCV(LogisticRegression(), param_reglog, cv=10,return_train_score=False, verbose=0)\n",
    "\n",
    "# Jeu de test\n",
    "reglog_best_score_test, reglog_best_param_test, reglog_best_estimator_test, cv_score_reglog_test =  fit_method(gs_cv_reglog, X_test, y_test_label)\n",
    "print('reglog_best_score_test:',reglog_best_score_test)\n",
    "\n",
    "# Jeu d'entrainement\n",
    "reglog_best_score_train, reglog_best_param_train, reglog_best_estimator_train, cv_score_reglog_train =  fit_method(gs_cv_reglog, X_train, y_train_label)\n",
    "print('reglog_best_score_train:',reglog_best_score_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNeighboors hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "gs_cv_knn = GridSearchCV(KNeighborsClassifier(), param_knn, cv=10,return_train_score=False, verbose=0)\n",
    "\n",
    "# Jeu de test\n",
    "knn_best_score_test, knn_best_param_test, knn_best_estimator_test, cv_score_knn_test =  fit_method(gs_cv_knn, X_test, y_test_label)\n",
    "print('knn_best_score_test:', knn_best_score_test)\n",
    "\n",
    "# Jeu d'entrainement\n",
    "knn_best_score_train, knn_best_param_train, knn_best_estimator_train, cv_score_knn_train =  fit_method(gs_cv_knn, X_train, y_train_label)\n",
    "print('knn_best_score_train:', knn_best_score_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "gs_cv_rf = GridSearchCV(RandomForestClassifier(), param_random_forest, cv=10,return_train_score=False, verbose=0, n_jobs=-1)\n",
    "\n",
    "# Jeu de test\n",
    "rf_best_score_test, rf_best_param_test, rf_best_estimator_test, cv_score_rf_test =  fit_method(gs_cv_rf, X_test, y_test_label)\n",
    "print('rf_best_score_test:', rf_best_score_test)\n",
    "\n",
    "# Jeu d'entrainement\n",
    "rf_best_score_train, rf_best_param_train, rf_best_estimator_train, cv_score_rf_train =  fit_method(gs_cv_rf, X_train, y_train_label)\n",
    "print('rf_best_score_train:', rf_best_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "gs_cv_perceptron = GridSearchCV(Perceptron(), param_perceptron, cv=10,return_train_score=False, verbose=0)\n",
    "\n",
    "# Jeu de test\n",
    "perceptron_best_score_test, perceptron_best_param_test, perceptron_best_estimator_test, cv_score_perceptron_test =  fit_method(gs_cv_perceptron, X_test, y_test_label)\n",
    "print('perceptron_best_score_test:', perceptron_best_score_test)\n",
    "\n",
    "# Jeu d'entrainement\n",
    "perceptron_best_score_train, perceptron_best_param_train, perceptron_best_estimator_train, cv_score_perceptron_train =  fit_method(gs_cv_perceptron, X_train, y_train_label)\n",
    "print('perceptron_best_score_train:', perceptron_best_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descente de Gradient Stochastique hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "gs_cv_dgs = GridSearchCV(SGDClassifier(), param_descente, cv=10,return_train_score=False, verbose=0)\n",
    "\n",
    "# Jeu de test\n",
    "dgs_best_score_test, dgs_best_param_test, dgs_best_estimator_test, cv_score_dgs_test =  fit_method(gs_cv_dgs, X_test, y_test_label)\n",
    "print('dgs_best_score_test:', dgs_best_score_test)\n",
    "\n",
    "# Jeu d'entrainement\n",
    "dgs_best_score_train, dgs_best_param_train, dgs_best_estimator_train, cv_score_dgs_train =  fit_method(gs_cv_dgs, X_train, y_train_label)\n",
    "print('dgs_best_score_train:', dgs_best_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_param = {\n",
    "    'Algorithmes': [\"Logisitic Regression\", \"KNN\", \"RandomForest\", \"Perceptron\", \"Descente de gradient stochastique\"],\n",
    "    'Best_param': [reglog_best_param_train, knn_best_param_train, rf_best_param_train, perceptron_best_param_train, dgs_best_param_train],\n",
    "    'Best_estimator': [reglog_best_estimator_train, knn_best_estimator_train, rf_best_estimator_train, perceptron_best_estimator_train, dgs_best_estimator_train],\n",
    "    'Cross-Validation score Train': [cv_score_reglog_train, cv_score_knn_train, cv_score_rf_train, cv_score_perceptron_train, cv_score_dgs_train]\n",
    "}\n",
    "hyperparameter = pd.DataFrame(data=data_param)\n",
    "hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall et précision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On définie ici nos fonctions pour plot et de transfo\n",
    "# Convertir une liste avec des 'No' & 'Yes' en 0 & 1 liste\n",
    "def transform_binary(table):\n",
    "    y_pred_binary = []\n",
    "    \n",
    "    for item in table:\n",
    "        if item == 'No':\n",
    "            y_pred_binary.append(0)\n",
    "        else:\n",
    "            y_pred_binary.append(1)\n",
    "    return y_pred_binary\n",
    "\n",
    "# Plot courbes de précision et recall vs Threshold\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b-\", label=\"Precision\", linewidth=2)\n",
    "    plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)\n",
    "    plt.xlabel(\"Threshold\", fontsize=16)\n",
    "    plt.legend(loc=\"upper left\", fontsize=16)\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "# Plot courbes de précision et recall\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls, precisions, \"k-\", linewidth=2)\n",
    "    plt.xlabel(\"Recall\", fontsize=16)\n",
    "    plt.ylabel(\"Precision\", fontsize=16)\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "\n",
    "# Plot de la courbe de Roc\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate', fontsize=16)\n",
    "    plt.ylabel('True Positive Rate', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affiche les informations pour un modèle donnée\n",
    "def displayInfo_by_model(estimator_train, estimator_test, X_train, y_true_train, X_test, y_true_test, method, xlim_x, xlim_y, ylim_x, ylim_y ):\n",
    "    # Fix random\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Print les infos de base (précision, recall, f1...)\n",
    "    y_pred_train = cross_val_predict(estimator_train, X_train, y_true_train, cv=7)\n",
    "    precision_train = precision_score(y_true_train, y_pred_train)\n",
    "    recall_train = recall_score(y_true_train, y_pred_train)\n",
    "    f1_train = f1_score(y_true_train, y_pred_train)\n",
    "    \n",
    "    y_pred_test = cross_val_predict(estimator_test, X_test, y_true_test, cv=7)\n",
    "    precision_test = precision_score(y_true_test, y_pred_test)\n",
    "    recall_test = recall_score(y_true_test, y_pred_test)\n",
    "    f1_test =  f1_score(y_true_test, y_pred_test)\n",
    "    \n",
    "    data_train_test = {\n",
    "    'Analyse': [\"precision_score\", \"recall_score\", \"f1_score\"],\n",
    "    \"Jeu d'entrainement\": [precision_train, recall_train, f1_train],\n",
    "    \"Jeu de test\": [precision_test, recall_test, f1_test],\n",
    "    'Différence': [precision_train - precision_test, recall_train - recall_test, f1_train - f1_test]\n",
    "    }\n",
    "        \n",
    "    result_train_test = pd.DataFrame(data=data_train_test)\n",
    "    display(result_train_test)\n",
    "    \n",
    "    \n",
    "    # Afficher courbes\n",
    "    y_scores = cross_val_predict(estimator_train, X_train, y_true_train, cv=7,method=method)\n",
    "    if(method == 'predict' or method == 'predict_proba'):\n",
    "        y_scores = y_scores[:,1]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y_true_train, y_scores)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "    plt.xlim([xlim_x,xlim_y])\n",
    "    plt.ylim([ylim_x,ylim_y])\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_precision_vs_recall(precisions, recalls)\n",
    "    plt.show()   \n",
    "\n",
    "    fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true_train, y_scores)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    plt.show()\n",
    "    \n",
    "    return fpr, tpr, fscore, thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_label = y_test.copy()\n",
    "y_test_label.where(y_test_label == \"Yes\", 0, inplace=True)\n",
    "y_test_label.where(y_test_label == 0, 1, inplace=True)\n",
    "y_test_label = y_test_label.astype(np.int64)\n",
    "y_test_label_true = (y_test_label == 1)\n",
    "\n",
    "y_train_label = y_train.copy()\n",
    "y_train_label.where(y_train_label == \"Yes\", 0, inplace=True)\n",
    "y_train_label.where(y_train_label == 0, 1, inplace=True)\n",
    "y_train_label = y_train_label.astype(np.int64)\n",
    "y_train_label = (y_train_label == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_reglog, tpr_reglog, fscore_reglog, thresholds_reglog = displayInfo_by_model(reglog_best_estimator_train, reglog_best_estimator_test, X_train, y_train_label, X_test, y_test_label_true,\"decision_function\",-2,0,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_knn, tpr_knn, fscore_knn, thresholds_knn = displayInfo_by_model(knn_best_estimator_train, knn_best_estimator_test, X_train, y_train_label, X_test, y_test_label_true,\"predict_proba\", 0.25,0.45,0.8,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_rf, tpr_rf, fscore_rf, thresholds_rf = displayInfo_by_model(rf_best_estimator_train, rf_best_estimator_test, X_train, y_train_label, X_test, y_test_label_true,\"predict_proba\", 0.1,0.6,0.8,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_perceptron, tpr_perceptron, fscore_perceptron, thresholds_perceptron = displayInfo_by_model(perceptron_best_estimator_train, perceptron_best_estimator_test, X_train, y_train_label, X_test, y_test_label_true,\"decision_function\", -10,10, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descente de gradient stochastique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_dgs, tpr_dgs, fscore_dgs, thresholds_dgs = displayInfo_by_model(dgs_best_estimator_train, dgs_best_estimator_test, X_train, y_train_label, X_test, y_test_label_true,\"decision_function\", -2, 0, 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plot_roc_curve(fpr_rf, tpr_rf, \"Random Forest\")\n",
    "plot_roc_curve(fpr_knn, tpr_knn, \"KNN\")\n",
    "plot_roc_curve(fpr_reglog, tpr_reglog, \"Logistic Regression\")\n",
    "plot_roc_curve(fpr_perceptron, tpr_perceptron, \"Perceptron\")\n",
    "plot_roc_curve(fpr_dgs, tpr_dgs, \"Descente de Gradient Stochastique\")\n",
    "plt.legend(loc=\"lower right\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def percentage(unique, counts):\n",
    "    return (counts[1]/(counts[0]+counts[1]))*100\n",
    "\n",
    "ix = argmax(fscore_rf)\n",
    "\n",
    "final_model = rf_best_estimator_train\n",
    "final_threshold = thresholds_rf[ix]\n",
    "\n",
    "final_prediction = final_model.predict_proba(X_train)[:, 1]\n",
    "final_prediction_set = np.where(final_prediction < final_threshold, 0, 1)\n",
    "\n",
    "unique, counts = np.unique(final_prediction_set, return_counts=True)\n",
    "dict(zip(unique, counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage(unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons donc voir que notre modèle prédit correctement l'attrition sur notre jeu de données, l'attrition étant sur celui-ci de 16%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Suite à notre prédiction, nous pouvons mettre en évidence les différentes features qui influent sur l'attrition, et donc le taux de turn-over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_estimator_train.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = dict(sorted(zip(X.columns, list(rf_best_estimator_train.feature_importances_)), reverse=True))\n",
    "feature_dict_sorted_A = sorted(feature_dict.items(), key=lambda x:x[1], reverse=True)\n",
    "feature_dict_sorted_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame(feature_dict, index=[0])\n",
    "feature_df.T.plot.barh(figsize=(20,12),title=\"Feature Importance\", legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces différentes fonctions nous permettent donc de mettre en évidence ces features (au dessus de 0.06), qui sont :\n",
    "* MeanTimeWorkOverYear2015\n",
    "* TotalWorkingYears\n",
    "* MonthlyIncome\n",
    "* YearsAtCompany\n",
    "* DistanceFromHome\n",
    "\n",
    "Nous allons donc parmis ces 5 features choisir celles qui peuvent être influencée par l'entreprise, `YearsAtCompany` et `TotalWorkingYears` ne permettant pas de solution facile à mettre en place nous n'allons pas les étudier ici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etude des features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MeanTimeWorkOverYear2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons étudier dans quels cas les employées sont plus susceptibles de quitter l'entreprise en fonction de leur temps moyen de travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_chart(final_data, 'MeanTimeWorkOverYear2015')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir les tendances suivantes grâce à ce graphique :\n",
    "* Les employées dont la moyenne est comprise entre 4h à 7h de travail ont tendance à ne pas quitter l'entreprise.\n",
    "* Les employées dont la moyenne est comprise entre 8h à 10h ont tendance à plus quitter l'entreprise. \n",
    "\n",
    "Nous allons donc simuler un réduction des horaires de travail pour observer si cela nous permet de réduire significativement l'attrition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi voir que si les employées travaillent 30 minutes de moins par jour (soit 2h30 par semaines) on peut faire descendre l'attrition à **14,6%** au lieu de 16% auparavant. Cette piste est viable, car en adaptant les horaires des salariées, l'entreprise peut diminuer significativement l'attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MonthlyIncome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons étudier dans quels cas les employées sont plus susceptibles de quitter l'entreprise en fonction de leur salaire par mois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_chart(final_data, 'MonthlyIncome')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir deux tendances grâce à ce graphique :\n",
    "* Les employées dont le salaire est inférieur à 50000 roupies sont plus susceptible de quitter l'entreprise.\n",
    "* Les employées dont le salaire est supérieur à 50000 roupies ont tendance à rester dans l'entreprise. \n",
    "\n",
    "Nous allons donc simuler une augmentation des salaires pour les employées ciblés pour voir si cela influera significativement notre attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois le modèle entrainé, en simulant une augmentation de 25% du salaire de nos employées, nous avons pu obtenir une attrition de **14.36%**. Cette piste peut donc elle aussi être mise en place par l'entreprise pour réduire son attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DistanceFromHome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons étudier dans quels cas les employées sont plus susceptibles de quitter l'entreprise en fonction de la distance entre leurs lieux de résidences et leur travail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(final_data[\"DistanceFromHome\"], final_data.Attrition).plot(kind=\"bar\",figsize=(10, 6))\n",
    "plt.title(\"Attrition en fonction de DistanceFromHome\")\n",
    "plt.xlabel(\"DistanceFromHome\")\n",
    "plt.ylabel(\"F\")\n",
    "plt.legend([\"No\", \"Yes\"])\n",
    "plt.xticks(rotation=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce graphique nous apprend que la distance entre les domiciles des salariées et l'entreprise n'influe pas sur l'attrition, seulement certains cas comme 15km et 19km. Cette feature étant que significative nous allons quand même effectuer une signification, prenant en compte la mise en place de télétravail pour les salariées à hauteur de 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons pu entrainer le modèle pour obtenir les résultats suivants : **14.6%** d'attrition, en mettant 25% du temps les salariées en télétravail. Cette piste peut donc être suivit par l'entreprise pour diminuer son attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pistes à suivre\n",
    "Nous avons donc vu que trois des nos cinqs paramètres peuvent être adapté pour réduire l'attrition. Nous pouvons donc proposer des solutions pour ceux-ci :\n",
    "* MeanTimeWorkOverYear2015 : Réduction de 30min/jour du temps de travail.\n",
    "* TotalWorkingYears : *Pas prise en compte car les salairiés agés vont à la retraite*\n",
    "* MonthlyIncome : Augmentation des salaires de 25%.\n",
    "* YearsAtCompany : Mise en place de prime d'ancienneté plus conséquente.\n",
    "* DistanceFromHome : Mise en place de télétravail à hauteur de 1,25j/semaine).\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
