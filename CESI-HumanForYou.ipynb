{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CESI HumanForYou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports des librairies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy.random import default_rng\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage des graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stabilité du notebook d'une exécution à l'autre\n",
    "random=default_rng(42) \n",
    "\n",
    "# jolies figures directement dans le notebook\n",
    "plt.rcParams['figure.figsize'] = [15,10] \n",
    "plt.rcParams[\"figure.dpi\"] = 250\n",
    "plt.rcParams['axes.labelsize'] = 6\n",
    "plt.rcParams['xtick.labelsize'] = 8\n",
    "plt.rcParams['ytick.labelsize'] = 8\n",
    "\n",
    "# où sauver les figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\") # le dossier doit exister\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des données depuis Github de Anthony Lorendeaux\n",
    "general_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/general_data.csv\"\n",
    "manager_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/manager_survey_data.csv\"\n",
    "employee_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/employee_survey_data.csv\"\n",
    "in_time_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/in_time.csv\"\n",
    "out_time_url = \"https://raw.githubusercontent.com/anthonylorendeaux/CESI-IA-CSV/master/out_time.csv\"\n",
    "\n",
    "#Lecture des csv\n",
    "general_info_data = pd.read_csv(general_url)\n",
    "manager_survey_data = pd.read_csv(manager_url)\n",
    "employee_survey_data = pd.read_csv(employee_url)\n",
    "in_time_data = pd.read_csv(in_time_url)\n",
    "out_time_data = pd.read_csv(out_time_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données\n",
    "Dans un premier temps, nous pouvons observer les premières lignes de notre dataset en utilisant la méthode **head()**, afin de vérifier que l'import se soit bien passé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_info_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons obtenir une description du dataset avec la méthode **info()**. \n",
    "Ce qui nous permettra de repérer les attributs contenant des données vides et de connaitre le type des valeurs de chaque attribut.\n",
    "\n",
    "La fonction **shape()** quand à elle nous permet combien de ligne et de colonne nous avons dans notre csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of in_time :',general_info_data.shape)\n",
    "general_info_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_survey_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of in_time :',manager_survey_data.shape)\n",
    "manager_survey_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_survey_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of in_time :',employee_survey_data.shape)\n",
    "employee_survey_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_time_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of in_time :',in_time_data.shape)\n",
    "in_time_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_time_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of in_time :',out_time_data.shape)\n",
    "out_time_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation des données\n",
    "\n",
    "Les données de temps ne sont pas exploitables dans l'état actuel des choses, il faut donc les retravailler.\n",
    "Les ddonnées sont pas expoitables il faut les tranformer.\n",
    "\n",
    "Avoir des heures d'entrées et de sortie de nos employés n'est pas trop significatifs, c'est pour cela que l' on va remplacer tous les valeurs par la moyenne de temps de travail de chaque employé.\n",
    "\n",
    "Mais : \n",
    "Les dates sont stockées en tant que chaine de caractère et c'est compliqué de les exploiter.\n",
    "Certaines données valent (NaN), ce qui veut dire qu'un employé a été absent au travail\n",
    "Il faut les transformer en objet datetime.\n",
    "\n",
    "Lorsqu'un employé est absent au travail, son temps moyen de travail est de 0 donc on peut remplacer les NaN par 0.\n",
    "\n",
    "D'abord on va rename la colonne Unnamed qui correspond à nos ID de nos employés puisque dans csv on a le même nombre de ligne que sur les autres csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On rename nos colonnes Unnamed de nos csv in et out\n",
    "in_time_data.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
    "in_time_data.set_index('EmployeeID', inplace=True)\n",
    "in_time_data\n",
    "out_time_data.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
    "out_time_data.set_index('EmployeeID', inplace=True)\n",
    "\n",
    "# On enlève les colonnes de vacances(là où il y a que des NaN) et donc là ou l'employé a été absent\n",
    "in_time_data=in_time_data.dropna(axis=1,how='all')\n",
    "out_time_data=out_time_data.dropna(axis=1,how='all')\n",
    "#On remplace les NaN par 0\n",
    "in_time_data.fillna(0, inplace=True)\n",
    "out_time_data.fillna(0, inplace=True)\n",
    "\n",
    "out_time_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On transforme nos chaines de caractère en objets datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in in_time_data.columns:\n",
    "    in_time_data[date]=pd.to_datetime(in_time_data[date])\n",
    "    out_time_data[date]=pd.to_datetime(out_time_data[date])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule dans un nouveau dataset le nombre d'heure passée au travail d'un employé par jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_work_per_day=pd.DataFrame()\n",
    "\n",
    "cols=in_time_data.columns\n",
    "for col in cols:\n",
    "    time_work_per_day[col]=((out_time_data[col] - in_time_data[col]).dt.total_seconds() /3600)\n",
    "\n",
    "time_work_per_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute ensuite une colonne pour avoir la moyenne de temps passsé au travail par employé sur l'année 2015 et le nombre d'absences au travail par employé durant l'année 2015 et on garde que nos colonnes de la moyenne et des absences sur le dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_work_per_day['MeanTimeWorkOverYear2015']=round(time_work_per_day.astype(int).mean(axis=1),2)\n",
    "time_work_per_day['absences_par_jour']=(time_work_per_day == 0).astype(int).sum(axis=1)\n",
    "time_work_per_day = time_work_per_day.drop((time_work_per_day.columns[0:-2]), axis = 1)\n",
    "time_work_per_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concaténation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_time_csv = general_info_data.merge(time_work_per_day, on='EmployeeID')\n",
    "concat_manager_csv = concat_time_csv.merge(manager_survey_data, on='EmployeeID')\n",
    "temp_concat = concat_manager_csv.merge(employee_survey_data, on='EmployeeID')\n",
    "temp_concat = temp_concat.set_index('EmployeeID')\n",
    "temp_concat.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = temp_concat.copy()\n",
    "final_data[final_data.columns[final_data.isnull().any()]].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.fillna(round(final_data.median()),inplace=True)\n",
    "final_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot\n",
    "final_data2 = pd.get_dummies(final_data, \n",
    "prefix=[\"BusinessTravel\",\"Department\",\"EducationField\", \"JobRole\",\"MaritalStatus\", \"Gender\"],\n",
    "columns=[\"BusinessTravel\",\"Department\",\"EducationField\", \"JobRole\",\"MaritalStatus\", \"Gender\"])\n",
    "final_data2.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete colums\n",
    "final_data2.drop(['EmployeeCount', 'Over18', 'StandardHours'], axis=1, inplace = True)\n",
    "final_data2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques pour l'attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BusinessTravel', 'Department', 'Education', 'EducationField', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus', 'StockOptionLevel', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance']\n",
    "\n",
    "plt.figure()\n",
    "for i, col in enumerate(cols):\n",
    "    ax = plt.subplot(7, 2, i+1)\n",
    "    plots = sns.histplot(data=final_data, x=col, ax=ax, hue=final_data['Attrition'], multiple='dodge', shrink=0.8)\n",
    "    # for bar in plots.patches:\n",
    "    #     percentage = '{:.1f}%'.format(100 * bar.get_height() / len(final_data[col]))\n",
    "    #     x = bar.get_x() + bar.get_width() / 2\n",
    "    #     y = bar.get_height()\n",
    "    #     plots.annotate(percentage, (x, y),ha='center',va='center',size=15, xytext=(0, 3),\n",
    "    #                textcoords='offset points')\n",
    "# plt.tight_layout(pad=3.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrice de corrélation\n",
    "corr_matrix = final_data2.corr(method=\"pearson\")\n",
    "\n",
    "plt.figure(figsize=(20,16))\n",
    "sns.heatmap(corr_matrix, cbar=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
